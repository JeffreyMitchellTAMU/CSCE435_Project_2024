{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Roundtrip module could not be loaded. Requires jupyter notebook version <= 7.x.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/scratch/group/csce435-f24/python-3.10.4/lib/python3.10/site-packages\")\n",
    "sys.path.append(\"/scratch/group/csce435-f24/thicket\")\n",
    "from glob import glob\n",
    "from tabulate import tabulate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import thicket as th\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common variables\n",
    "processes = [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "input_size = [65536, 262144, 1048576, 4194304, 16777216, 67108864, 2**28]\n",
    "input_type = [\"Sorted\", \"ReverseSorted\", \"Random\", \"1_perc_perturbed\"]\n",
    "measurement_regions = ['main', 'comp_large', 'comm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/2) Reading Files: 100%|██████████████████████| 70/70 [00:02<00:00, 24.08it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████████████| 69/69 [00:00<00:00, 193.23it/s]\n",
      "/home/jeffrey/anaconda3/lib/python3.12/site-packages/thicket/ensemble.py:409: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace({numerical_fill_value: None}, inplace=True)\n",
      "(1/2) Reading Files: 100%|██████████████████████| 70/70 [00:02<00:00, 24.73it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████████████| 69/69 [00:00<00:00, 183.85it/s]\n",
      "/home/jeffrey/anaconda3/lib/python3.12/site-packages/thicket/ensemble.py:409: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace({numerical_fill_value: None}, inplace=True)\n",
      "(1/2) Reading Files: 100%|██████████████████████| 70/70 [00:02<00:00, 25.49it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████████████| 69/69 [00:00<00:00, 194.05it/s]\n",
      "/home/jeffrey/anaconda3/lib/python3.12/site-packages/thicket/ensemble.py:409: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace({numerical_fill_value: None}, inplace=True)\n",
      "(1/2) Reading Files: 100%|██████████████████████| 70/70 [00:02<00:00, 25.02it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████████████| 69/69 [00:00<00:00, 152.07it/s]\n",
      "/home/jeffrey/anaconda3/lib/python3.12/site-packages/thicket/ensemble.py:409: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace({numerical_fill_value: None}, inplace=True)\n",
      "(1/2) Reading Files: 100%|████████████████████████| 6/6 [00:00<00:00, 24.07it/s]\n",
      "(2/2) Creating Thicket: 100%|████████████████████| 5/5 [00:00<00:00, 312.48it/s]\n",
      "/home/jeffrey/anaconda3/lib/python3.12/site-packages/thicket/ensemble.py:409: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace({numerical_fill_value: None}, inplace=True)\n",
      "(1/2) Reading Files: 100%|████████████████████████| 7/7 [00:00<00:00, 21.18it/s]\n",
      "(2/2) Creating Thicket: 100%|████████████████████| 6/6 [00:00<00:00, 356.94it/s]\n",
      "/home/jeffrey/anaconda3/lib/python3.12/site-packages/thicket/ensemble.py:409: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace({numerical_fill_value: None}, inplace=True)\n",
      "(1/2) Reading Files: 100%|████████████████████████| 7/7 [00:00<00:00, 22.83it/s]\n",
      "(2/2) Creating Thicket: 100%|████████████████████| 6/6 [00:00<00:00, 366.06it/s]\n",
      "/home/jeffrey/anaconda3/lib/python3.12/site-packages/thicket/ensemble.py:409: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace({numerical_fill_value: None}, inplace=True)\n",
      "(1/2) Reading Files:  43%|██████████▎             | 3/7 [00:00<00:00, 21.00it/s]"
     ]
    }
   ],
   "source": [
    "bitonic_tk = {}\n",
    "for in_type in input_type:\n",
    "    bitonic_tk[in_type] = th.Thicket.from_caliperreader(glob(\"../bitonic_ipynb/Bitonic_Cali/*-{}.cali\".format(in_type)))\n",
    "sample_tk = {}\n",
    "for in_type in input_type:\n",
    "    sample_tk[in_type] = th.Thicket.from_caliperreader(glob(\"../sample_ipynb/cali/*-s{}*.cali\".format(in_type)))\n",
    "merge_tk = {}\n",
    "for in_type in input_type:\n",
    "    merge_tk[in_type] = th.Thicket.from_caliperreader(glob(\"../merge_ipynb/Merge_Cali/*-{}.cali\".format(in_type)))\n",
    "radix_tk = {}\n",
    "for in_type in input_type:\n",
    "    radix_tk[in_type] = th.Thicket.from_caliperreader(glob(\"../radix_ipynb/Radix_Cali/*-s{}.cali\".format(in_type)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Calltree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Not very useful if counting from multiple cali files:\n",
    "#print(tk.tree(metric_column=\"Avg time/rank\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tk.metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tk.metadata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for node in tk['Random'].graph.traverse():\n",
    "#    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tk['Random'].dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Performance data by `input_size` in the Thicket metadata table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tk in [bitonic_tk, sample_tk, merge_tk, radix_tk]:\n",
    "    for in_type in tk:\n",
    "        tk[in_type].metadata_column_to_perfdata(\"num_procs\")\n",
    "        tk[in_type].metadata_column_to_perfdata(\"input_size\")\n",
    "        #tk.metadata_column_to_perfdata(\"input_type\")\n",
    "\n",
    "        tk[in_type].dataframe = tk[in_type].dataframe.reset_index().set_index([\"node\", \"num_procs\", \"input_size\"]).sort_index()\n",
    "\n",
    "        #tk.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change font size for all plots\n",
    "plt.rcParams.update({\"font.size\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tk.dataframe.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for graphing in matplotlib:\n",
    "def show_mpl_plot(fig, ax, title, xlabel, ylabel, legend, ylim=None, ylog=False):\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if (legend):\n",
    "        ax.legend(legend)\n",
    "    else:\n",
    "        ax.legend()\n",
    "    plt.xscale(\"log\", base=2)\n",
    "    plt.xticks(processes)\n",
    "    ax.set_xticklabels(processes)\n",
    "\n",
    "    if (ylog):\n",
    "        plt.yscale(\"log\", base=10)\n",
    "    \n",
    "    if (ylim):\n",
    "        plt.ylim(ylim)\n",
    "    else:\n",
    "        plt.ylim(bottom=0)\n",
    "    \n",
    "    plt.savefig(f'plots/{title}')\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_mpl(df, title, xlabel, ylabel, legend, ylim=None):\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(\n",
    "        df,\n",
    "        marker='o',\n",
    "    )\n",
    "    return show_mpl_plot(fig, ax, title, xlabel, ylabel, legend, ylim=ylim)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each implementation:\n",
    "- For each of comp_large, comm, and main:\n",
    "    - Strong scaling plots for each input_size with lines for input_type (7\n",
    "    plots - 4 lines each)\n",
    "    - Strong scaling speedup plot for each input_type (4 plots)\n",
    "    - Weak scaling plots for each input_type (4 plots)\n",
    "\n",
    "- in Radix Sort case, chose to forgo and only have the 6 plots as last problem size would exceed 6 hours (not ideal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge sort will have $3 \\cdot (7 + 4 + 4) = 45$ plots.\n",
    "(However, at the time of writing, Grace has a network error that prevents `p=1024` jobs from running. Thus, 18 `p=1024` Caliper files are still missing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Scaling\n",
    "- fixed problem size while increasing number of processors/nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through nodes, and if comp_large, comm, or main, print the strong scaling\n",
    "title_template = \"Multi-algorithm Strong Scaling ({}, {}, n={})\"#, scaled for synchronized y limits)\"\n",
    "for node in merge_tk['Random'].graph.traverse():\n",
    "\n",
    "    if node.frame['name'] == 'main' or node.frame['name'] == 'comp_large' or node.frame['name'] == 'comm':\n",
    "        # for input size n, plot 4 plots for each input_type\n",
    "        for arySize in [2**26, 2**28]:\n",
    "\n",
    "            in_type = 'Random'\n",
    "\n",
    "            fig = plt.figure(figsize=(15,7))\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            \n",
    "            # title will be node.frame['name']_input_size\n",
    "            title = title_template.format(node.frame['name'], in_type, arySize)\n",
    "\n",
    "            #for in_type in input_type:\n",
    "            for name, tk in [('Bitonic', bitonic_tk), ('Sample', sample_tk), ('Merge', merge_tk), ('Radix', radix_tk)]:\n",
    "                df = tk[in_type].dataframe.loc[node, 'Avg time/rank'] # get average time\n",
    "                df = (df.loc[df.index.get_level_values('input_size') == arySize])\n",
    "                df = (df.loc[df.index.get_level_values('num_procs') != 1])\n",
    "                #df = df.unstack(level=\"input_type\")\n",
    "                df = df.unstack(level=\"input_size\")\n",
    "                ax.plot(df, marker='o', label=name)\n",
    "                \n",
    "            show_mpl_plot(fig, ax, title, \"Processes\", \"Time (s)\", None,\n",
    "                          #ylim=(0, 15200), # Synchronized with other groupmates\n",
    "                          #ylim=(0, 112.5), # Synchronized only with merge sort strong scaling\n",
    "                          ylim=(2**-3, 2**14),\n",
    "                          ylog=True,\n",
    "                         )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Scaling Speedup for each input type\n",
    "- For this, we will do fixed size speedup for the $S_p =\\frac{T_2}{T_p}$ for each input_type given problem size $2^{26}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through nodes, and if comp_large, comm, or main, print the strong scaling\n",
    "title_template0 = \"Multi-algorithm Strong Scaling Speedup ({}, {}, n={})\"#, scaled for synchronized y limits)\"\n",
    "\n",
    "scales = {'main': 8, 'comm': 8, 'comp_large': 79}\n",
    "\n",
    "for node in merge_tk['Random'].graph.traverse():\n",
    "    if node.frame['name'] == 'main' or node.frame['name'] == 'comp_large' or node.frame['name'] == 'comm':\n",
    "        # for input size n, plot 4 plots for each input_type\n",
    "        print(node.frame['name'])\n",
    "\n",
    "        itype = 'Random'\n",
    "        \n",
    "        #for itype in input_type:\n",
    "        for n in [2**26, 2**28]:\n",
    "            # title will be node.frame['name']_input_size\n",
    "            title = title_template0.format(node.frame['name'], itype, n)\n",
    "\n",
    "            fig = plt.figure(figsize=(15,7))\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "            for name, tk in [\n",
    "                ('Bitonic', bitonic_tk),\n",
    "                #('Sample', sample_tk), # TODO: Upload the remaining Sample Sort Caliper files\n",
    "                ('Merge', merge_tk),\n",
    "                ('Radix', radix_tk),\n",
    "            ]:\n",
    "                if (n == 2**28 and name == 'Radix'):\n",
    "                    continue\n",
    "                \n",
    "                df = tk[itype].dataframe.loc[node, 'Avg time/rank'] # get average time\n",
    "                #df = (df.loc[df.index.get_level_values('input_type') == itype])\n",
    "                df = (df.loc[df.index.get_level_values('num_procs') >= 2])\n",
    "                #df = (df.loc[df.index.get_level_values('num_procs') < 1024])\n",
    "\n",
    "                df = (df.loc[df.index.get_level_values('input_size') == n])\n",
    "            \n",
    "                df = df.unstack(level=\"input_size\")\n",
    "                #df = df.unstack(level=\"input_type\")\n",
    "                twoProcTimes = (df.loc[df.index.get_level_values('num_procs') == 2].values)[0]\n",
    "\n",
    "                for i in range(0,len(twoProcTimes)):\n",
    "                    twoProc = twoProcTimes[i]\n",
    "                    df[n] = (df[n] / (2*twoProc))**-1\n",
    "\n",
    "                ax.plot(df, marker='o', label=name)\n",
    "\n",
    "            show_mpl_plot(fig, ax, title, \"Processes\", \"Speedup\", None,\n",
    "                          #ylim=(0, 15200), # Synchronized with other groupmates\n",
    "                          ylim=(1/3.5, 160), # Synchronized only with merge sort strong scaling\n",
    "                          #ylim=(2**-3, 2**14),\n",
    "                          ylog=True,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Scaling plots for each input type\n",
    "- Increasing the problem size and processors\n",
    "- Following our original plan from report section 2c: n=2^20/p=4, n=2^22/p=16, n=2^24/p=64, n=2^26/p=256, n=2^28/p=1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through nodes, and if comp_large, comm, or main, print the strong scaling\n",
    "title_template0 = \"Multi-algorithm Weak Scaling ({})\"#, scaled for synchronized y limits)\"\n",
    "\n",
    "np_pairs = [(2**20, 4), (2**22, 16), (2**24, 64), (2**26, 256), (2**28, 1024)]\n",
    "\n",
    "# For use when 1024-processor runs are unavailable, for example because Grace broke.\n",
    "# This can also be useful if an algorithm doesn't work with 2^28 array elements:\n",
    "np_pairs_backup = [(2**18, 2), (2**20, 8), (2**22, 32), (2**24, 128), (2**26, 512)]\n",
    "#np_pairs_backup = [(x*4, y) for x, y in np_pairs_backup]\n",
    "np_pairs = np_pairs_backup\n",
    "\n",
    "x_labels = ['n={}\\np={}'.format(n, p) for n, p in np_pairs]\n",
    "\n",
    "bitonic_data = {}\n",
    "sample_data = {}\n",
    "merge_data = {}\n",
    "radix_data = {}\n",
    "\n",
    "data = bitonic_data\n",
    "for itype in input_type:\n",
    "    data[itype] = {region: [] for region in measurement_regions}\n",
    "\n",
    "    for n, p in np_pairs:\n",
    "        path = \"../bitonic_ipynb/Bitonic_Cali/p{}-a{}-{}.cali\".format(p, n, itype)\n",
    "        print(path)\n",
    "        tk_tmp = th.Thicket.from_caliperreader(glob(path))\n",
    "        tk_tmp.metadata_column_to_perfdata(\"num_procs\")\n",
    "        tk_tmp.metadata_column_to_perfdata(\"input_size\")\n",
    "        for node in tk_tmp.graph.traverse():\n",
    "            if (node.frame['name'] not in measurement_regions):\n",
    "                continue\n",
    "\n",
    "            value = list(tk_tmp.dataframe.loc[node, 'Avg time/rank'])[0]\n",
    "            #print(value)\n",
    "            data[itype][node.frame['name']].append(value)\n",
    "            \n",
    "'''data = sample_data\n",
    "for itype in input_type:\n",
    "    data[itype] = {region: [] for region in measurement_regions}\n",
    "\n",
    "    for n, p in np_pairs:\n",
    "        path = \"../sample_ipynb/cali/n{}-p{}-s{}-*.cali\".format(n, p, itype)\n",
    "        print(path)\n",
    "        tk_tmp = th.Thicket.from_caliperreader(glob(path))\n",
    "        tk_tmp.metadata_column_to_perfdata(\"num_procs\")\n",
    "        tk_tmp.metadata_column_to_perfdata(\"input_size\")\n",
    "        for node in tk_tmp.graph.traverse():\n",
    "            if (node.frame['name'] not in measurement_regions):\n",
    "                continue\n",
    "\n",
    "            value = list(tk_tmp.dataframe.loc[node, 'Avg time/rank'])[0]\n",
    "            #print(value)\n",
    "            data[itype][node.frame['name']].append(value)'''\n",
    "            \n",
    "data = merge_data\n",
    "for itype in input_type:\n",
    "    data[itype] = {region: [] for region in measurement_regions}\n",
    "\n",
    "    for n, p in np_pairs:\n",
    "        path = \"../merge_ipynb/Merge_Cali/n{}-p{}-{}.cali\".format(n, p, itype)\n",
    "        print(path)\n",
    "        tk_tmp = th.Thicket.from_caliperreader(glob(path))\n",
    "        tk_tmp.metadata_column_to_perfdata(\"num_procs\")\n",
    "        tk_tmp.metadata_column_to_perfdata(\"input_size\")\n",
    "        for node in tk_tmp.graph.traverse():\n",
    "            if (node.frame['name'] not in measurement_regions):\n",
    "                continue\n",
    "\n",
    "            value = list(tk_tmp.dataframe.loc[node, 'Avg time/rank'])[0]\n",
    "            #print(value)\n",
    "            data[itype][node.frame['name']].append(value)\n",
    "            \n",
    "data = radix_data\n",
    "for itype in input_type:\n",
    "    data[itype] = {region: [] for region in measurement_regions}\n",
    "\n",
    "    for n, p in np_pairs:\n",
    "        path = \"../radix_ipynb/Radix_Cali/p{}-a{}-s{}.cali\".format(p, n, itype)\n",
    "        print(path)\n",
    "        tk_tmp = th.Thicket.from_caliperreader(glob(path))\n",
    "        tk_tmp.metadata_column_to_perfdata(\"num_procs\")\n",
    "        tk_tmp.metadata_column_to_perfdata(\"input_size\")\n",
    "        for node in tk_tmp.graph.traverse():\n",
    "            if (node.frame['name'] not in measurement_regions):\n",
    "                continue\n",
    "\n",
    "            value = list(tk_tmp.dataframe.loc[node, 'Avg time/rank'])[0]\n",
    "            #print(value)\n",
    "            data[itype][node.frame['name']].append(value)\n",
    "    # Iron out the Radix data:\n",
    "    print(radix_data[itype]['comm'])\n",
    "    for i in range(len(radix_data[itype]['comm'])-1, 0, -2):\n",
    "        radix_data[itype]['comm'][i-1] += radix_data[itype]['comm'].pop(i)\n",
    "    print(radix_data[itype]['comm'])\n",
    "\n",
    "for region in measurement_regions:\n",
    "\n",
    "    title = title_template0.format(region)\n",
    "\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    t = 'Random'\n",
    "    \n",
    "    for name, data in [('Bitonic', bitonic_data), ('Sample', sample_data), ('Merge', merge_data), ('Radix', radix_data)]:\n",
    "        if (not data):\n",
    "            continue\n",
    "        ax.plot(range(len(data[t][region])), data[t][region], label=name, marker='o')\n",
    "                          \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Configuration')\n",
    "    ax.set_ylabel('Time (s)')\n",
    "    ax.legend()#legend)\n",
    "    #plt.xscale(\"log\", base=2)\n",
    "    plt.xticks(range(len(np_pairs)))\n",
    "    ax.set_xticklabels(x_labels)\n",
    "\n",
    "    plt.yscale(\"log\", base=10)\n",
    "    plt.ylim(bottom=0)\n",
    "    #plt.ylim((0, 1600)) # Synchronized with groupmates\n",
    "    #plt.ylim((0, 4.75)) # Synchronized only with merge weak scaling\n",
    "    \n",
    "    plt.savefig(f'plots/{title}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
